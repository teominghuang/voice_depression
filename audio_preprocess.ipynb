{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess speech sound with background noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n",
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.functional as F\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "\n",
    "#from torchaudio.transforms import AudioEffectsChain\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "SAMPLE_WAV = download_asset(\"tutorial-assets/steam-train-whistle-daniel_simon.wav\")\n",
    "SAMPLE_RIR = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\n",
    "SAMPLE_SPEECH = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-src-sp0307-ch127535-sg0042-8000hz.wav\")\n",
    "SAMPLE_NOISE = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load FFmpeg 6 extension.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 128, in _find_ffmpeg_extension\n",
      "    return _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 113, in _find_versionsed_ffmpeg_extension\n",
      "    _try_access_avutil(ffmpeg_ver)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 89, in _try_access_avutil\n",
      "    torchaudio.lib._torchaudio.find_avutil(libavutil)\n",
      "RuntimeError: error in LoadLibrary for avutil-58.dll. WinError 126: The specified module could not be found.\n",
      "\n",
      "Failed to load FFmpeg 5 extension.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 128, in _find_ffmpeg_extension\n",
      "    return _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 113, in _find_versionsed_ffmpeg_extension\n",
      "    _try_access_avutil(ffmpeg_ver)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 89, in _try_access_avutil\n",
      "    torchaudio.lib._torchaudio.find_avutil(libavutil)\n",
      "RuntimeError: error in LoadLibrary for avutil-57.dll. WinError 126: The specified module could not be found.\n",
      "\n",
      "Failed to load FFmpeg 4 extension.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 128, in _find_ffmpeg_extension\n",
      "    return _find_versionsed_ffmpeg_extension(ffmpeg_ver)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 115, in _find_versionsed_ffmpeg_extension\n",
      "    _load_lib(library)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py\", line 64, in _load_lib\n",
      "    torch.ops.load_library(path)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_ops.py\", line 852, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "  File \"c:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ctypes\\__init__.py\", line 374, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "FileNotFoundError: Could not find module 'C:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchaudio\\lib\\libtorchaudio_ffmpeg4.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "StreamWriter requires FFmpeg extension which is not available. Please refer to the stacktrace above for how to resolve this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py:226\u001b[0m, in \u001b[0;36m_fail_since_no_ffmpeg.<locals>.wrapped\u001b[1;34m(*_args, **_kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[39m# Note:\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     \u001b[39m# We run _init_ffmpeg again just to show users the stacktrace.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[39m# _init_ffmpeg would not succeed here.\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     _init_ffmpeg(show_error\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py:162\u001b[0m, in \u001b[0;36m_init_ffmpeg\u001b[1;34m(show_error)\u001b[0m\n\u001b[0;32m    160\u001b[0m         ffmpeg_vers \u001b[39m=\u001b[39m [ffmpeg_ver]\n\u001b[1;32m--> 162\u001b[0m ext \u001b[39m=\u001b[39m _find_ffmpeg_extension(ffmpeg_vers, show_error)\n\u001b[0;32m    163\u001b[0m ext\u001b[39m.\u001b[39minit()\n",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py:132\u001b[0m, in \u001b[0;36m_find_ffmpeg_extension\u001b[1;34m(ffmpeg_vers, show_error)\u001b[0m\n\u001b[0;32m    131\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to intialize FFmpeg extension. Tried versions: \u001b[39m\u001b[39m{\u001b[39;00mffmpeg_vers\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to intialize FFmpeg extension. Tried versions: ['6', '5', '4']",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\benny\\Desktop\\Y4S1\\Deep_Speech_Technology\\Project\\audio_preprocess.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     effector \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mAudioEffector(effect\u001b[39m=\u001b[39meffect)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m effector\u001b[39m.\u001b[39mapply(waveform, sample_rate)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m waveform2 \u001b[39m=\u001b[39m apply_effect(waveform1, sample_rate, effect)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mprint\u001b[39m(waveform1\u001b[39m.\u001b[39mshape, sample_rate)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mprint\u001b[39m(waveform2\u001b[39m.\u001b[39mshape, sample_rate)\n",
      "\u001b[1;32mc:\\Users\\benny\\Desktop\\Y4S1\\Deep_Speech_Technology\\Project\\audio_preprocess.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_effect\u001b[39m(waveform, sample_rate, effect):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m#effector = AudioEffectsChain(effects=[effect])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     effector \u001b[39m=\u001b[39m torchaudio\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mAudioEffector(effect\u001b[39m=\u001b[39meffect)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/audio_preprocess.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m effector\u001b[39m.\u001b[39;49mapply(waveform, sample_rate)\n",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\io\\_effector.py:313\u001b[0m, in \u001b[0;36mAudioEffector.apply\u001b[1;34m(self, waveform, sample_rate, output_sample_rate)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mif\u001b[39;00m waveform\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    311\u001b[0m     \u001b[39mreturn\u001b[39;00m waveform\n\u001b[1;32m--> 313\u001b[0m reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_reader(waveform, sample_rate, output_sample_rate)\n\u001b[0;32m    314\u001b[0m reader\u001b[39m.\u001b[39mprocess_all_packets()\n\u001b[0;32m    315\u001b[0m (applied,) \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39mpop_chunks()\n",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\io\\_effector.py:275\u001b[0m, in \u001b[0;36mAudioEffector._get_reader\u001b[1;34m(self, waveform, sample_rate, output_sample_rate, frames_per_chunk)\u001b[0m\n\u001b[0;32m    272\u001b[0m     option \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msample_rate\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msample_rate\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mchannels\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnum_channels\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m}\n\u001b[0;32m    274\u001b[0m \u001b[39mif\u001b[39;00m frames_per_chunk \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     src \u001b[39m=\u001b[39m _encode(waveform, sample_rate, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meffect, muxer, encoder, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcodec_config)\n\u001b[0;32m    276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     src \u001b[39m=\u001b[39m _AudioStreamingEncoder(\n\u001b[0;32m    278\u001b[0m         waveform, sample_rate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meffect, muxer, encoder, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcodec_config, frames_per_chunk\n\u001b[0;32m    279\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\io\\_effector.py:98\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(src, sample_rate, effect, muxer, encoder, codec_config)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode\u001b[39m(\n\u001b[0;32m     90\u001b[0m     src: Tensor,\n\u001b[0;32m     91\u001b[0m     sample_rate: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m     codec_config: Optional[CodecConfig],\n\u001b[0;32m     96\u001b[0m ):\n\u001b[0;32m     97\u001b[0m     buffer \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[1;32m---> 98\u001b[0m     writer \u001b[39m=\u001b[39m StreamWriter(buffer, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mmuxer)\n\u001b[0;32m     99\u001b[0m     writer\u001b[39m.\u001b[39madd_audio_stream(\n\u001b[0;32m    100\u001b[0m         num_channels\u001b[39m=\u001b[39msrc\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m),\n\u001b[0;32m    101\u001b[0m         sample_rate\u001b[39m=\u001b[39msample_rate,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m         codec_config\u001b[39m=\u001b[39mcodec_config,\n\u001b[0;32m    106\u001b[0m     )\n\u001b[0;32m    107\u001b[0m     \u001b[39mwith\u001b[39;00m writer\u001b[39m.\u001b[39mopen():\n",
      "File \u001b[1;32mc:\\Users\\benny\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\_extension\\utils.py:228\u001b[0m, in \u001b[0;36m_fail_since_no_ffmpeg.<locals>.wrapped\u001b[1;34m(*_args, **_kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     _init_ffmpeg(show_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    227\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 228\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    229\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m requires FFmpeg extension which is not available. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease refer to the stacktrace above for how to resolve this.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[39m# This should not happen in normal execution, but just in case.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39m_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_kwargs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: StreamWriter requires FFmpeg extension which is not available. Please refer to the stacktrace above for how to resolve this."
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "#SAMPLE_WAV = \"C:/Users/benny/Desktop/Y4S1/Deep_Speech_Technology/Project/data/sample/steam-train-whistle-daniel_simon.wav\"\n",
    "waveform1, sample_rate = torchaudio.load(SAMPLE_WAV, channels_first=False)\n",
    "\n",
    "# Define effects\n",
    "effect = \",\".join(\n",
    "    [\n",
    "        \"lowpass=frequency=300:poles=1\",  # apply single-pole lowpass filter\n",
    "        \"atempo=0.8\",  # reduce the speed\n",
    "        \"aecho=in_gain=0.8:out_gain=0.9:delays=200:decays=0.3|delays=400:decays=0.3\"\n",
    "        # Applying echo gives some dramatic feeling\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Apply effects\n",
    "def apply_effect(waveform, sample_rate, effect):\n",
    "    #effector = AudioEffectsChain(effects=[effect])\n",
    "    effector = torchaudio.io.AudioEffector(effect=effect)\n",
    "    return effector.apply(waveform, sample_rate)\n",
    "\n",
    "\n",
    "waveform2 = apply_effect(waveform1, sample_rate, effect)\n",
    "\n",
    "print(waveform1.shape, sample_rate)\n",
    "print(waveform2.shape, sample_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 16000\n",
    "original_speech, sample_rate = torchaudio.load(SAMPLE_SPEECH)\n",
    "\n",
    "#plot_specgram(original_speech, sample_rate, title=\"Original\")\n",
    "\n",
    "# Apply RIR\n",
    "rir_applied = F.fftconvolve(speech, rir)\n",
    "\n",
    "#plot_specgram(rir_applied, sample_rate, title=\"RIR Applied\")\n",
    "\n",
    "# Add background noise\n",
    "# Because the noise is recorded in the actual environment, we consider that\n",
    "# the noise contains the acoustic feature of the environment. Therefore, we add\n",
    "# the noise after RIR application.\n",
    "noise, _ = torchaudio.load(SAMPLE_NOISE)\n",
    "noise = noise[:, : rir_applied.shape[1]]\n",
    "\n",
    "snr_db = torch.tensor([8])\n",
    "bg_added = F.add_noise(rir_applied, noise, snr_db)\n",
    "\n",
    "#plot_specgram(bg_added, sample_rate, title=\"BG noise added\")\n",
    "\n",
    "# Apply filtering and change sample rate\n",
    "effect = \",\".join(\n",
    "    [\n",
    "        \"lowpass=frequency=4000:poles=1\",\n",
    "        \"compand=attacks=0.02:decays=0.05:points=-60/-60|-30/-10|-20/-8|-5/-8|-2/-8:gain=-8:volume=-7:delay=0.05\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "filtered = apply_effect(bg_added.T, sample_rate, effect)\n",
    "sample_rate2 = 8000\n",
    "\n",
    "#plot_specgram(filtered.T, sample_rate2, title=\"Filtered\")\n",
    "\n",
    "# Apply telephony codec\n",
    "#codec_applied = apply_codec(filtered, sample_rate2, \"g722\")\n",
    "#plot_specgram(codec_applied.T, sample_rate2, title=\"G.722 Codec Applied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(noise, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

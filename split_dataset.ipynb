{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Filtering data\n",
    "Randomise dataset and filter them into databank consisting of 70% training data, 15% validation data, and 15% testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#receive all files from \n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying directory of main and relevant sets\n",
    "- Do change the target directory as per needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the main directory\n",
    "main_directory = os.getcwd() + '\\\\EATD-Corpus\\\\'\n",
    "\n",
    "# Specify the directory to copy files to\n",
    "target_trainset = os.getcwd() + '\\\\data\\\\training_set\\\\'\n",
    "target_valiset = os.getcwd() + '\\\\data\\\\validation_set\\\\'\n",
    "target_testset = os.getcwd() + '\\\\data\\\\testing_set\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into 70-15-15 (Training-Validation-Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an element tagged to file order in directory and shuffle order to funnel to relevant folders\n",
    "ntotal = 162\n",
    "list = [i for i in range(1, 163)]\n",
    "random.shuffle(list)\n",
    "\n",
    "# Split data into 70% training, 15% validation and 15% testing\n",
    "n_testdata = math.ceil(ntotal * 0.15)\n",
    "n_validata = math.ceil(ntotal * 0.15)\n",
    "\n",
    "train_data = list[n_validata+n_testdata:]\n",
    "vali_data = list[:n_validata] \n",
    "test_data = list[n_validata:n_validata+n_testdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112,)\n",
      "[52, 79, 59, 69, 141, 48, 73, 146, 56, 61, 63, 68, 88, 6, 58, 54, 89, 39, 134, 43, 103, 33, 51, 7, 129, 55, 137, 24, 130, 81, 125, 105, 71, 18, 16, 112, 120, 40, 11, 67, 10, 131, 126, 151, 132, 70, 27, 150, 53, 158, 86, 97, 119, 162, 117, 91, 135, 62, 100, 127, 157, 92, 83, 64, 115, 93, 8, 45, 85, 65, 49, 109, 102, 107, 113, 114, 149, 29, 87, 21, 123, 124, 77, 90, 22, 121, 38, 41, 108, 144, 66, 60, 26, 111, 31, 35, 23, 138, 1, 99, 14, 80, 37, 139, 44, 78, 42, 128, 152, 133, 122, 104]\n",
      "[72, 76, 46, 145, 116, 15, 156, 106, 32, 94, 3, 30, 140, 84, 20, 34, 50, 13, 5, 153, 101, 36, 17, 136, 95]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(list[n_validata+n_testdata:]))\n",
    "print(train_data)\n",
    "print(vali_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funnel data directories from EATD-Corpus to relevant folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benny\\Desktop\\Y4S1\\Deep_Speech_Technology\\Project\\EATD-Corpus\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segregation Complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(main_directory)\n",
    "i = 1\n",
    "# Loop through all folders in the main directory\n",
    "for folder_name in os.listdir(main_directory):\n",
    "    #Joins folder name with the main directory\n",
    "    folder_path = os.path.join(main_directory, folder_name)\n",
    "    folder_path = folder_path + '\\\\'\n",
    "\n",
    "    # Check if the item in the directory is a folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        target_folder = \"\"\n",
    "        if (i in vali_data):\n",
    "            target_folder = os.path.join(target_valiset, folder_name) \n",
    "        elif (i in test_data):\n",
    "            target_folder = os.path.join(target_testset, folder_name)\n",
    "        else:\n",
    "            target_folder = os.path.join(target_trainset, folder_name)\n",
    "        \n",
    "        #Check if there is some issue segregating into target folder\n",
    "        if target_folder == \"\":\n",
    "            print(\"Problem with segregating data into target folder\")\n",
    "            break\n",
    "\n",
    "        #If folder does not exist, make directory\n",
    "        if not os.path.exists(target_folder):\n",
    "            os.makedirs(target_folder)\n",
    "\n",
    "        #Copy all files from data folder to target folder\n",
    "        copy_tree(folder_path, target_folder)\n",
    "        i += 1\n",
    "\n",
    "print(\"Segregation Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compile dataset information in CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify directory of datasets and import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "# Specify the main directory\n",
    "main_data = os.getcwd() + '\\\\data\\\\'\n",
    "\n",
    "# Specify the directory to copy files to\n",
    "target_trainset = os.getcwd() + '\\\\data\\\\training_set\\\\'\n",
    "target_valiset = os.getcwd() + '\\\\data\\\\validation_set\\\\'\n",
    "target_testset = os.getcwd() + '\\\\data\\\\testing_set\\\\'\n",
    "\n",
    "# Label file\n",
    "label_file = 'new_label.txt'\n",
    "# Types of responses in each folder\n",
    "responses = ['negative_out.wav', 'neutral_out.wav', 'positive_out.wav']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to list all folders in a directory\n",
    "def list_files(directory):\n",
    "    folders = []\n",
    "    for f in os.listdir(directory):\n",
    "        if os.path.isdir(os.path.join(directory, f)):\n",
    "            # Get label from label file\n",
    "            label = 0\n",
    "            label_input = os.path.join(directory, f, label_file)\n",
    "            if os.path.isfile(label_input):\n",
    "                with open(label_input, 'r') as input_txtf:\n",
    "                    score = float(input_txtf.read().strip())\n",
    "                    if score >=53:\n",
    "                        label = 1 \n",
    "            else:\n",
    "                    raise Exception(\"File not found: \" + label_input)\n",
    "\n",
    "            # Get all audio responses in the folder\n",
    "            for i in range (0, len(responses)):\n",
    "                if os.path.isfile(os.path.join(directory, f, responses[i])):\n",
    "                    folders.append((f + '\\\\' + responses[i], label))\n",
    "                else:\n",
    "                    print(\"Data file erased / Data file not found: \" + os.path.join(directory, f, responses[i]))\n",
    "    return folders\n",
    "\n",
    "# Function to save the folder names to a CSV file\n",
    "def save_to_csv(fname_labs, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['fname', 'label'])  # Write header\n",
    "\n",
    "        # Write each row with (fname, label) data\n",
    "        for fname_lab in fname_labs:\n",
    "            csv_writer.writerow([fname_lab[0], fname_lab[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file erased / Data file not found: c:\\Users\\benny\\Desktop\\Y4S1\\Deep_Speech_Technology\\Project\\data\\training_set\\v_79\\positive_out.wav\n",
      "Data file erased / Data file not found: c:\\Users\\benny\\Desktop\\Y4S1\\Deep_Speech_Technology\\Project\\data\\validation_set\\v_79\\positive_out.wav\n"
     ]
    }
   ],
   "source": [
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    csv_path = os.getcwd() + '\\\\data\\\\'\n",
    "    # Get a list of all folders in the specified directory\n",
    "    files_lab = list_files(target_trainset)\n",
    "    # Specify the CSV file name\n",
    "    csv_file = csv_path + 'training.csv'\n",
    "    # Save the folder names to a CSV file\n",
    "    save_to_csv(files_lab, csv_file)\n",
    "\n",
    "    # Get a list of all folders in the specified directory\n",
    "    files_lab = list_files(target_valiset)\n",
    "    # Specify the CSV file name\n",
    "    csv_file = csv_path + 'validation.csv'\n",
    "    # Save the folder names to a CSV file\n",
    "    save_to_csv(files_lab, csv_file)\n",
    "\n",
    "    # Get a list of all folders in the specified directory\n",
    "    files_lab = list_files(target_testset)\n",
    "    # Specify the CSV file name\n",
    "    csv_file = csv_path + 'testing.csv'\n",
    "    # Save the folder names to a CSV file\n",
    "    save_to_csv(files_lab, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Oversample minority class in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_folder = os.getcwd() + '\\\\data'\n",
    "\n",
    "train_path = os.getcwd() + '\\\\data\\\\training_set'\n",
    "vali_path = os.getcwd() + '\\\\data\\\\validation_set'\n",
    "test_path = os.getcwd() + '\\\\data\\\\testing_set'\n",
    "\n",
    "audio_train_folder = os.listdir(os.getcwd() + '\\\\data\\\\training_set')\n",
    "audio_vali_folder = os.listdir(os.getcwd() + '\\\\data\\\\validation_set')\n",
    "audio_test_folder = os.listdir(os.getcwd() + '\\\\data\\\\testing_set')\n",
    "\n",
    "traindf = pd.read_csv(os.getcwd() + '\\\\data\\\\training.csv')\n",
    "testdf = pd.read_csv(os.getcwd() + '\\\\data\\\\testing.csv')\n",
    "#submission = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "train_opfp = os.getcwd() + '\\\\data\\\\training_final.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels to split into minority and majority class\n",
    "targetcol = 'label'\n",
    "\n",
    "fname = traindf.drop(targetcol, axis=1)\n",
    "label = traindf[targetcol]\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_data = traindf[label == label.value_counts().idxmax()]\n",
    "minority_data = traindf[label == label.value_counts().idxmin()]\n",
    "\n",
    "resam_min_size = label.value_counts().max()\n",
    "\n",
    "# Resample the minority class to the specified size\n",
    "oversampler = RandomOverSampler(sampling_strategy={label.value_counts().idxmin(): resam_min_size}, random_state=0)\n",
    "fname_resam, label_resam = oversampler.fit_resample(fname, label)\n",
    "\n",
    "# Create a DataFrame with the resampled minority class\n",
    "balanced_data = pd.DataFrame()\n",
    "balanced_data['fname'] = fname_resam['fname']\n",
    "balanced_data[targetcol] = label_resam\n",
    "\n",
    "balanced_data.to_csv(train_opfp, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
